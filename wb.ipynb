{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from functools import lru_cache\n",
    "from typing import Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv(dotenv_path=\"./.env\")\n",
    "\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Configure basic logging for the application.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "\n",
    "\n",
    "class LLMSettings(BaseModel):\n",
    "    \"\"\"Base settings for Language Model configurations.\"\"\"\n",
    "\n",
    "    temperature: float = 0.0\n",
    "    max_tokens: Optional[int] = None\n",
    "    max_retries: int = 3\n",
    "\n",
    "\n",
    "class OpenAISettings(LLMSettings):\n",
    "    \"\"\"OpenAI-specific settings extending LLMSettings.\"\"\"\n",
    "\n",
    "    api_key: str = Field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\"))\n",
    "    default_model: str = Field(default=\"gpt-4o\")\n",
    "    embedding_model: str = Field(default=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class DatabaseSettings(BaseModel):\n",
    "    \"\"\"Database connection settings.\"\"\"\n",
    "\n",
    "    service_url: str = Field(default_factory=lambda: os.getenv(\"TIMESCALE_SERVICE_URL\"))\n",
    "\n",
    "\n",
    "class VectorStoreSettings(BaseModel):\n",
    "    \"\"\"Settings for the VectorStore.\"\"\"\n",
    "\n",
    "    table_name: str = \"embeddings\"\n",
    "    embedding_dimensions: int = 1536\n",
    "    time_partition_interval: timedelta = timedelta(days=7)\n",
    "\n",
    "\n",
    "class Settings(BaseModel):\n",
    "    \"\"\"Main settings class combining all sub-settings.\"\"\"\n",
    "\n",
    "    openai: OpenAISettings = Field(default_factory=OpenAISettings)\n",
    "    database: DatabaseSettings = Field(default_factory=DatabaseSettings)\n",
    "    vector_store: VectorStoreSettings = Field(default_factory=VectorStoreSettings)\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def get_settings() -> Settings:\n",
    "    \"\"\"Create and return a cached instance of the Settings.\"\"\"\n",
    "    settings = Settings()\n",
    "    setup_logging()\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding the Vectorstore from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from timescale_vector import client\n",
    "import pandas as pd\n",
    "\n",
    "def initialize_clients(settings):\n",
    "\t\"\"\"Initializing all necessary clients.\"\"\"\n",
    "\t\n",
    "\t# Initializing VectorStore\n",
    "\tservice_url = settings.database.service_url\n",
    "\ttable_name = settings.vector_store.table_name\n",
    "\tembedding_dimensions = settings.vector_store.embedding_dimensions\n",
    "\ttime_partition_interval = settings.vector_store.time_partition_interval\n",
    "\n",
    "\t# Creating vectorstore connection using timescale\n",
    "\tvec_client = client.Sync(\n",
    "\t\tservice_url=service_url,\n",
    "\t\ttable_name=table_name,\n",
    "\t\tnum_dimensions=embedding_dimensions,\n",
    "\t\ttime_partition_interval=time_partition_interval\n",
    "\t)\n",
    "\n",
    "\t# Initializing OpenAI Client\n",
    "\topenai_api_key = settings.openai.api_key\n",
    "\topenai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\t# Initializing Embedding Model\n",
    "\tembeddding_model = settings.openai.embedding_model\n",
    "\n",
    "\treturn vec_client, openai_client, embeddding_model\n",
    "\n",
    "\n",
    "def get_embedding(openai_client, embeddding_model, text):\n",
    "\t\"\"\"Function to create embeddings.\"\"\"\n",
    "\n",
    "\t# Removing \\n with space\n",
    "\ttext = text.replace('\\n', ' ')\n",
    "\t# Creating Embedding\n",
    "\tembedding = (openai_client.embeddings.create(input=[text], model=embeddding_model).data[0].embedding)\n",
    "\n",
    "\treturn embedding\n",
    "\n",
    "def create_tables(vec_client):\n",
    "\t\"\"\"Function to create table.\"\"\"\n",
    "\n",
    "\t# Creating table using vector client\n",
    "\tvec_client.create_tables()\n",
    "\t\n",
    "def create_index(vec_client):\n",
    "\t\"\"\"Function to create embedding index.\"\"\"\n",
    "\n",
    "\t# Creating Embedding Index using DiskAnnIndex\n",
    "\tvec_client.create_embedding_index(client.DiskAnnIndex())\n",
    "\t\n",
    "def drop_index(vec_client):\n",
    "\t\"\"\"Function to drop embedding index.\"\"\"\n",
    "\n",
    "\t# Dropping Embedding Index\n",
    "\tvec_client.drop_embedding_index()\n",
    "\n",
    "def upsert(vec_client, df):\n",
    "\t\"\"\"Function to upload/insert dataframe with embeddings to table.\"\"\"\n",
    "\n",
    "\t# Converting dadtaframe to records\n",
    "\trecords = df.to_records(index=False)\n",
    "\n",
    "\t# Inserting the records to table\n",
    "\tvec_client.upsert(list(records))\n",
    "\n",
    "def create_dataframe_from_results(results):\n",
    "\t\"\"\"Function to convert the queried results as dataframe.\"\"\"\n",
    "\t\n",
    "\t# Creating dataframe from list of tuples\n",
    "\tresults = pd.DataFrame(results, columns=['id', 'metadata', 'content', 'embedding', 'distance'])\n",
    "\n",
    "\t# Typecasting id column to string\n",
    "\tresults['id'] = results['id'].astype(str)\n",
    "\n",
    "\treturn results\n",
    "\n",
    "def search(vec_client, query_text, limit, metadata_filter, predicates, time_range, return_dataframe):\n",
    "\t\"\"\"Function to search for Embeddings similar to input embedding.\"\"\"\n",
    "    \n",
    "\t# Converting input query to embedding\n",
    "\tquery_embedding = get_embedding(query_text)\n",
    "\n",
    "\t# Creating Search arguments dictionary\n",
    "\tsearch_args = {\n",
    "\t\t'limit': limit\n",
    "\t}\n",
    "\n",
    "\t# Adding metadata filter to search arguments if available\n",
    "\tif metadata_filter:\n",
    "\t\tsearch_args['metadata_filter'] = metadata_filter\n",
    "\n",
    "\t# Adding predicates to search arguments if available\n",
    "\tif predicates:\n",
    "\t\tsearch_args['predicates'] = predicates\n",
    "\n",
    "\t# Adding time range to search arguments if available\n",
    "\tif time_range:\n",
    "\t\tstart_date, end_date = time_range\n",
    "\t\tsearch_args['uuid_time_filter'] = client.UUIDTimeRange(start_date, end_date)\n",
    "\n",
    "\t# Searching for most similar embeddings\n",
    "\tresults = vec_client.search(query_embedding, **search_args)\n",
    "\n",
    "\t# Returning dataframe with similar embeddings if set on\n",
    "\tif return_dataframe:\n",
    "\t\treturn create_dataframe_from_results(results)\n",
    "\telse:\n",
    "\t\treturn results\n",
    "\t\n",
    "def delete_records(vec_client, ids=None, metadata_filter=None, delete_all=None):\n",
    "\t\"\"\"Function to remove records from vector database.\"\"\"\n",
    "\t\n",
    "\t# Checking if multiple parameters are passed\n",
    "\tif sum(bool(x) for x in (ids, metadata_filter, delete_all)) != 1:\n",
    "\t\traise ValueError(\"Provide exactly one from: ids, metadata_filter, or delete_all\")\n",
    "\t\n",
    "\t# Deleting Records according to given conditions\n",
    "\tif delete_all:\n",
    "\t\tvec_client.delete_all()\n",
    "\telif ids:\n",
    "\t\tvec_client.delete_by_ids(ids)\n",
    "\telif metadata_filter:\n",
    "\t\tvec_client.delete_by_metadata(metadata_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = get_settings()\n",
    "vec_client, openai_client, embeddding_model = initialize_clients(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_records(vec_client, delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Module to insert data to Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 23:52:26,949 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 23:52:33,348 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 23:52:35,039 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 23:52:36,089 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 23:52:37,640 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "# from database.vector_store import VectorStore\n",
    "from timescale_vector.client import uuid_from_time\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"data/faq_dataset.csv\", sep=\";\")\n",
    "df = df.head(5)\n",
    "\n",
    "# Prepare data for insertion\n",
    "def prepare_record(row):\n",
    "    \"\"\"Prepare a record for insertion into the vector store.\n",
    "\n",
    "    This function creates a record with a UUID version 1 as the ID, which captures\n",
    "    the current time or a specified time.\n",
    "\n",
    "    Note:\n",
    "        - By default, this function uses the current time for the UUID.\n",
    "        - To use a specific time:\n",
    "          1. Import the datetime module.\n",
    "          2. Create a datetime object for your desired time.\n",
    "          3. Use uuid_from_time(your_datetime) instead of uuid_from_time(datetime.now()).\n",
    "\n",
    "        Example:\n",
    "            from datetime import datetime\n",
    "            specific_time = datetime(2023, 1, 1, 12, 0, 0)\n",
    "            id = str(uuid_from_time(specific_time))\n",
    "\n",
    "        This is useful when your content already has an associated datetime.\n",
    "    \"\"\"\n",
    "    content = f\"Question: {row['question']}\\nAnswer: {row['answer']}\"\n",
    "    embedding = get_embedding(openai_client, embeddding_model, content)\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"id\": str(uuid_from_time(datetime.now())),\n",
    "            \"metadata\": {\n",
    "                \"category\": row[\"category\"],\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "            },\n",
    "            \"contents\": content,\n",
    "            \"embedding\": embedding,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "records_df = df.apply(prepare_record, axis=1)\n",
    "# Create tables and insert data\n",
    "create_tables(vec_client)\n",
    "create_index(vec_client)  # DiskAnnIndex\n",
    "upsert(vec_client, records_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding LLMHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "from typing import List, Dict, Any, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Type\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class LLMHub:\n",
    "    \n",
    "\tdef __init__(self, provider: str):\n",
    "\t\t\"\"\"Constructor to Initialize LLMHub.\"\"\"\n",
    "\n",
    "\t\tself.provider = provider\n",
    "\t\tself.settings = getattr(get_settings(), self.provider)\n",
    "\t\tself.client = self._initialize_client()\n",
    "\n",
    "\tdef _initialize_client(self) -> Any:\n",
    "\t\t\"\"\"Function to initialize client.\"\"\"\n",
    "\n",
    "\t\t# Creating a dict of multiple LLM initializers\n",
    "\t\tclient_initializers = {\n",
    "\t\t\t'openai': lambda x: instructor.from_openai(OpenAI(api_key=x.api_key))\n",
    "\t\t}\n",
    "\n",
    "\t\t# Initializing selected initializer\n",
    "\t\tinitializer = client_initializers.get(self.provider)\n",
    "\n",
    "\t\t# Checking if initializer valid and returning client\n",
    "\t\tif initializer:\n",
    "\t\t\treturn initializer(self.settings)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Selected Provider not Available.\")\n",
    "\t\t\n",
    "\tdef create_completion(self, response_model: Type[BaseModel], messages: List[Dict[str, str]], **kwargs) -> Any:\n",
    "\t\t\"\"\"Function to get completion from LLM for given input.\"\"\"\n",
    "\n",
    "\t\t# Creating completion params from kwargs and inputs\n",
    "\t\tcompletion_params = {\n",
    "\t\t\t'model': kwargs.get('model', self.settings.default_model),\n",
    "\t\t\t'temperature': kwargs.get('temperature', self.settings.temperature),\n",
    "\t\t\t'max_retries': kwargs.get('max_retries', self.settings.max_retries),\n",
    "\t\t\t'max_tokens': kwargs.get('max_tokens', self.settings.max_tokens),\n",
    "\t\t\t'response_model': response_model,\n",
    "\t\t\t'messages': messages\n",
    "\t\t}\n",
    "\n",
    "\t\t# Creating completion\n",
    "\t\treturn self.client.chat.completions.create(**completion_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
